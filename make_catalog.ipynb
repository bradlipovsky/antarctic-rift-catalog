{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make an Antarctic Rift Catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Read the ATL06 files into a Python data structure\n",
    "Put the needed info in a dictionary, save the whole thing to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on the mask...\n",
      "     Loading existing ckdt.\n",
      "     Mask loaded after 7.327136 s\n",
      "ERROR: Key error, ATL06_20190407203152_01460310_004_01.h5\n",
      "ERROR: Key error, ATL06_20190407203152_01460310_004_01.h5\n",
      "ERROR: Key error, ATL06_20190407203152_01460310_004_01.h5\n",
      "ERROR: Key error, ATL06_20190407203152_01460310_004_01.h5\n",
      "ERROR: Key error, ATL06_20190527053933_09000312_004_01.h5\n",
      "ERROR: Key error, ATL06_20190527053933_09000312_004_01.h5\n",
      "ERROR: Key error, ATL06_20190527053933_09000312_004_01.h5\n",
      "ERROR: Key error, ATL06_20190527053933_09000312_004_01.h5\n",
      "ERROR: Key error, ATL06_20200618123724_12820712_004_01.h5\n",
      "ERROR: Key error, ATL06_20200618123724_12820712_004_01.h5\n",
      "ERROR: Key error, ATL06_20200810084911_07020812_004_01.h5\n",
      "ERROR: Key error, ATL06_20200810084911_07020812_004_01.h5\n",
      "ERROR: Key error, ATL06_20200810084911_07020812_004_01.h5\n",
      "ERROR: Key error, ATL06_20200810084911_07020812_004_01.h5\n",
      "ERROR: File not found,  ATL06_20210203112931_06331010_004_01.h5\n",
      "Time to read the H5 files:  19.021568157942966\n",
      "Time to apply ice shelf mask:  168.98991307104006\n",
      "Calculated tides in 352.847339 s.\n",
      "Time to save all of the data:  0.5892789949430153\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import arc\n",
    "import importlib\n",
    "importlib.reload(arc)\n",
    "import json\n",
    "\n",
    "shelf_name='brunt-riiser-ekstrom'\n",
    "\n",
    "atl06_file_name = './atl06_' + shelf_name + '-atl06.pkl'\n",
    "atl06_filelist = './filelists/' + shelf_name + '-list.json'\n",
    "dataset_path = '/data/fast0/'\n",
    "\n",
    "if os.path.isfile(atl06_file_name):\n",
    "    print(\"Data already saved, so there's no need to ingest data. \\\n",
    "To repeat the data ingest, it would probably be best to change the filename of the \\\n",
    "existing file.\")\n",
    "else:\n",
    "    with open(atl06_filelist,'rb') as handle:\n",
    "        filelist = json.load(handle)\n",
    "    arc.ingest(filelist,atl06_file_name,dataset_path)\n",
    "\n",
    "\n",
    "#ATLAS was on safehold from June 25 to July 25, 2019.  Did we download data from this time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.  Run the rift detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATL06 data loaded from pickle in 0.246610 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bradlipovsky/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:178: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/home/bradlipovsky/brunt-is2-rifts/arc.py:399: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  rift_h.append   ( row['h'][rift_coords[0]:rift_coords[1]].mean() - \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Found 4917 rifts.\n",
      "Time to detect rifts: 12.168543496052735\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Load data (deserialize)\n",
    "with open(atl06_file_name, 'rb') as handle:\n",
    "    atl06_data = pickle.load(handle)\n",
    "    print('ATL06 data loaded from pickle in %f s'%(time.perf_counter()-tt))\n",
    "\n",
    "\n",
    "# Find the rifts\n",
    "rift_obs = arc.get_rifts(atl06_data)\n",
    "\n",
    "# Store the rifts in a dataframe\n",
    "rift_obs=pd.DataFrame(rift_obs)\n",
    "\n",
    "# Or you could store it in a geopanda\n",
    "# import geopandas\n",
    "# rift_obs = geopandas.GeoDataFrame(rift_obs,\n",
    "#                              geometry=geopandas.points_from_xy(rift_obs['x-centroid'],\n",
    "#                                                                rift_obs['y-centroid']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Step 3. Save the rift_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rift_obs_output_file_name = shelf_name + '_rift_obs.pickle'\n",
    "with open(rift_obs_output_file_name, 'wb') as handle:\n",
    "    pickle.dump(rift_obs, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Steps.\n",
    "\n",
    "From this point, useful next steps are to quality control the data (notebook qc.ipynb) and to analyze the data (analyze_rift_measurements.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
