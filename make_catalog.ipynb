{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make an Antarctic Rift Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import arc\n",
    "import importlib\n",
    "importlib.reload(arc)\n",
    "import json\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Step 1. Read the ATL06 files into a Python data structure\n",
    "Put the needed info in a dictionary, save the whole thing to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "atl06_path = \"/data/fast1/arc/atl06\"\n",
    "filelist_path = \"/data/fast1/arc/filelists\"\n",
    "dataset_path = '/data/fast0/'\n",
    "output_path = '/data/fast1/arc/rift_obs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "==================================\n",
      " PROCESSING THE ATL06 DATA (brunt)\n",
      "==================================\n",
      "Data already saved, so there's no need to ingest data.\n",
      "To repeat the data ingest, it would probably be best\n",
      "to change the filename of the existing file.\n",
      " \n",
      "Current filename is: /data/fast1/arc/atl06/brunt.pkl\n",
      " \n",
      "DANGER ZONE: Type YES to overwrite:   NO\n"
     ]
    }
   ],
   "source": [
    "shelf_names = ['brunt']\n",
    "\n",
    "for shelf in shelf_names:\n",
    "    print(\" \")\n",
    "    print('==================================')\n",
    "    print(' PROCESSING THE ATL06 DATA (%s)'%shelf)\n",
    "    print('==================================')\n",
    "\n",
    "    atl06_file_name = os.path.join(atl06_path, shelf + '.pkl')\n",
    "    atl06_filelist = os.path.join(filelist_path, shelf + '-list.json')\n",
    "\n",
    "    with open(atl06_filelist,'rb') as handle:\n",
    "        filelist = json.load(handle)\n",
    "\n",
    "    arc.ingest(filelist,atl06_file_name,dataset_path)\n",
    "\n",
    "    # Load data\n",
    "    with open(atl06_file_name, 'rb') as handle:\n",
    "        atl06_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.  Run the rift detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bradlipovsky/notebooks/brunt-is2-rifts/arc.py:438: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  rift_h.append   ( row['h'][rift_coords[0]:rift_coords[1]].mean() - \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Found 25293 rifts.\n",
      "Time to detect rifts: 75.8161452501081\n"
     ]
    }
   ],
   "source": [
    "# Find the rifts\n",
    "rift_obs = arc.get_rifts(atl06_data)\n",
    "rift_obs=pd.DataFrame(rift_obs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Step 3. Save the rift_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/fast1/arc/rift_obs/brunt.pkl\n"
     ]
    }
   ],
   "source": [
    "rift_obs_output_file_name = os.path.join(output_path, shelf + '.pkl')\n",
    "with open(rift_obs_output_file_name, 'wb') as handle:\n",
    "    pickle.dump(rift_obs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print(rift_obs_output_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Steps.\n",
    "\n",
    "From this point, useful next steps are to quality control the data (notebook qc.ipynb) and to analyze the data (analyze_rift_measurements.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Cartopy)",
   "language": "python",
   "name": "cartopy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
